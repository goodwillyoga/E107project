---
title: "Stock_Twits_Sentiment_Analysis"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(readr)
library(stringr)
library(ggplot2)
library(broom)
library(lubridate)
library(ggrepel)

#Supress warnings
options(warn=-1)

#read stick-twits_sentiments generate from stock_twits_processing.R file
data <- read_csv(file = "https://raw.githubusercontent.com/goodwillyoga/E107project/master/pooja/data/stock_twits_sentiment_score3.csv")[-1]
colnames(data)[3] <- "createdat"

#Convert to UTC to EST time zone 
data <- data %>% mutate(utc.time = as.POSIXct(data$createdat, tz="UTC")) %>%
                 mutate(est.time = format(utc.time, tz="America/New_York")) %>%
                 mutate(est.date = substr(as.character(format(strftime(est.time, '%m/%d/%Y'))), 2,10)) %>%
                 mutate(est.hour = paste(est.date, hour(est.time)))
```

#### Exploratory Data Analysis Plots for tweet counts

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#EDA for tweet counts, sentiment score and symbols
data %>% 
  group_by(symbol) %>%
  summarize(tweet_counts = n()) %>%
  ggplot(aes(x=symbol, y=tweet_counts, size=tweet_counts)) + 
  geom_point(aes(color=symbol)) +
  geom_text_repel(aes(symbol, tweet_counts, label=symbol)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title="Tweet counts") +
  theme(legend.position = "none") 
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Percent change function
pcchange=function(x,lag=1) {
  c(diff(x,lag))/x
}

#Get hour from time function
get_24hour <- function(x){
  ret <- ''
  splitVector<- strsplit(x,':')
  ret <- sapply(splitVector, function(z){
    if(str_count(z[2],'AM')|str_count(z[2],'am')){
      paste( z[1])
    }else{
      paste( ifelse(as.numeric(z[1]) == 12,12, as.numeric(z[1])+12 ))
    }
  })
  return(ret)
}

# Scale function
scale<-function(m){
  (m - mean(m))/sd(m)
}

#Average sentiment score by hour
avg_sentiment_score_by_hour <- data %>% 
            group_by(symbol, dayhour = est.hour) %>%
            summarise(avg_score = mean(sentiment_score), tweet_counts = n()) %>%
            mutate(pchange_tweet_counts = pcchange(tweet_counts)) %>%
            mutate(pchange_avg_score = pcchange(avg_score)) %>%
            mutate(pchange_avg_score = ifelse(is.na(pchange_avg_score) | is.infinite(pchange_avg_score) |is.nan(pchange_avg_score), 0, pchange_avg_score)) %>%
            ungroup() %>%
            group_by(symbol) %>%
            mutate(scale_pchange_avg_score = scale(pchange_avg_score)) %>% 
            mutate(scale_pchange_tweet_counts = scale(pchange_tweet_counts)) %>% 
            mutate(scale_pchange_avg_score = ifelse(is.na(scale_pchange_avg_score) | is.infinite(scale_pchange_avg_score) |is.nan(scale_pchange_avg_score), 0, scale_pchange_avg_score)) %>%
            ungroup() %>%
            select(symbol, dayhour, avg_score, tweet_counts, scale_pchange_avg_score, scale_pchange_tweet_counts) %>%
            unique() 

#Average sentiment score by day
avg_sentiment_score_by_day <- data %>% 
            group_by(symbol, day=est.date) %>%
            summarise(avg_score = mean(sentiment_score), tweet_counts = n()) %>%
            mutate(pchange_tweet_counts = pcchange(tweet_counts)) %>%
            mutate(pchange_avg_score = pcchange(avg_score)) %>%
            mutate(pchange_avg_score = ifelse(is.na(pchange_avg_score) | is.infinite(pchange_avg_score) |is.nan(pchange_avg_score), 0, pchange_avg_score)) %>%
            ungroup() %>%
            group_by(symbol) %>%
            mutate(scale_pchange_avg_score = scale(pchange_avg_score)) %>% 
            mutate(scale_pchange_tweet_counts = scale(pchange_tweet_counts)) %>% 
            mutate(scale_pchange_avg_score = ifelse(is.na(scale_pchange_avg_score) | is.infinite(scale_pchange_avg_score) |is.nan(scale_pchange_avg_score), 0, scale_pchange_avg_score)) %>%
            ungroup() %>%
            select(symbol, day, avg_score, tweet_counts, scale_pchange_avg_score, scale_pchange_tweet_counts) %>%
            unique() 
 
#Load YAHOO finance data
load("/Users/poojasingh/Documents/HE107/E107project/pulkit/yahoo-finance.RData")

##Average Stock Price by hour
avg_stocks_price_by_hour <- stocks %>% 
                   mutate(dayhour = paste(lastTradeDate,get_24hour(lastTradeTime))) %>%
                   group_by(symbol, dayhour) %>%
                   summarise(price = mean(price)) %>%
                   mutate(pchange_price_change = pcchange(price)) %>%
                   mutate(pchange_price_change = ifelse(is.na(pchange_price_change) | is.infinite(pchange_price_change) |is.nan(pchange_price_change), 0, pchange_price_change)) %>%
                   ungroup() %>%
                   group_by(symbol) %>%
                   mutate(scale_pchange_price_change = scale(pchange_price_change)) %>% 
                   mutate(scale_pchange_price_change = ifelse(is.na(scale_pchange_price_change) | is.infinite(scale_pchange_price_change) |is.nan(scale_pchange_price_change), 0, scale_pchange_price_change)) %>%
                   ungroup() %>%
                   select(symbol, dayhour, price, scale_pchange_price_change) %>%
                   unique()

#Average Stock Price by day
avg_stocks_price_by_day <- stocks %>% 
                  group_by(symbol, day=lastTradeDate) %>%
                  summarise(price = mean(price), volume = max(volume)) %>%
                  mutate(pchange_price_change = pcchange(price)) %>%
                  mutate(pchange_volume = pcchange(volume)) %>%
                  mutate(pchange_price_change = ifelse(is.na(pchange_price_change) | is.infinite(pchange_price_change) |is.nan(pchange_price_change), 0, pchange_price_change)) %>%
                  mutate(pchange_volume = ifelse(is.na(pchange_volume) | is.infinite(pchange_volume) |is.nan(pchange_volume), 0, pchange_volume)) %>%
                  ungroup() %>%
                  group_by(symbol) %>%
                  mutate(scale_pchange_price_change = scale(pchange_price_change)) %>% 
                  mutate(scale_pchange_volume = scale(pchange_volume)) %>% 
                  mutate(scale_pchange_price_change = ifelse(is.na(scale_pchange_price_change) | is.infinite(scale_pchange_price_change) |is.nan(scale_pchange_price_change), 0, scale_pchange_price_change)) %>%
                  mutate(scale_pchange_volume = ifelse(is.na(scale_pchange_volume) | is.infinite(scale_pchange_volume) |is.nan(scale_pchange_volume), 0, scale_pchange_volume)) %>%
                  ungroup() %>%
                  select(symbol, day, price, scale_pchange_price_change, scale_pchange_volume) %>%
                  unique()

#Join score and price
dat <- inner_join(avg_stocks_price_by_hour, avg_sentiment_score_by_hour)
dat.byday <- inner_join(avg_stocks_price_by_day, avg_sentiment_score_by_day)

#Plot overlay denisty plots for perchange change in stock price and percent change in sentiment_score
dat3 <- subset(dat, symbol=="EIX")
dat3 <- data.frame(Normalized_Percent_Change_By_Hour = c(dat3$scale_pchange_price_change, dat3$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat3$scale_pchange_price_change)))
dat3 <- cbind(dat3, symbol="EIX")

dat4 <- subset(dat, symbol=="GS")
dat4 <- data.frame(Normalized_Percent_Change_By_Hour = c(dat4$scale_pchange_price_change, dat4$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat4$scale_pchange_price_change)))
dat4 <- cbind(dat4, symbol="GS")

dat5 <- subset(dat, symbol=="IBM")
dat5 <- data.frame(Normalized_Percent_Change_By_Hour = c(dat5$scale_pchange_price_change, dat5$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat5$scale_pchange_price_change)))
dat5 <- cbind(dat5, symbol="IBM")

#Plot overlay denisty plots for perchange change in stock price and percent change in sentiment_score
dat6 <- subset(dat.byday, symbol=="EIX")
dat6 <- data.frame(Normalized_Percent_Change_By_Day = c(dat6$scale_pchange_price_change, dat6$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat6$scale_pchange_price_change)))
dat6 <- cbind(dat6, symbol="EIX")

dat7 <- subset(dat.byday, symbol=="GS")
dat7 <- data.frame(Normalized_Percent_Change_By_Day = c(dat7$scale_pchange_price_change, dat7$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat7$scale_pchange_price_change)))
dat7 <- cbind(dat7, symbol="GS")

dat8 <- subset(dat.byday, symbol=="IBM")
dat8 <- data.frame(Normalized_Percent_Change_By_Day = c(dat8$scale_pchange_price_change, dat8$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat8$scale_pchange_price_change)))
dat8 <- cbind(dat8, symbol="IBM")
```

#### Density plot of normalized hourly percent change in sentiment score and price change 

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#Overlay Density Plot
datz <- rbind(dat6, dat7, dat8)
datz %>% 
  ggplot(aes(x = Normalized_Percent_Change_By_Day, fill = lines)) + geom_density(alpha = 0.5) + 
  facet_wrap(~symbol) +
  theme(legend.position="bottom")

#Overlay Density Plot
datz <- rbind(dat3, dat4, dat5)
datz %>% 
  ggplot(aes(x = Normalized_Percent_Change_By_Hour, fill = lines)) + geom_density(alpha = 0.5) + 
  facet_wrap(~symbol) +
  theme(legend.position="bottom")
```

#### Plot p-values for linear regression fit model

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Fit linear models - avg_score + tweet_counts by hour
fits1 <- dat %>%
  group_by(symbol) %>%
  do(mod = lm(price ~ avg_score + tweet_counts, data = .))

results1 <- tidy(fits1, mod) %>% filter(term=='avg_score') 

#Plot p-values and see symbols that have significant results
results1 %>% 
  ggplot(aes(symbol, p.value, color=symbol)) + geom_point() + geom_hline(yintercept = .05, color = 'red') +
  geom_text_repel(aes(symbol, p.value, label=symbol), data = filter(results1,  p.value <.05 )) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("P-values for Price by Hour") +
  theme(legend.position = "none") 

#Fit linear models - percent change in avg_score + tweet_counts by hour
fits2 <- dat %>%
  group_by(symbol) %>%
  do(mod = lm(scale_pchange_price_change ~ scale_pchange_avg_score + scale_pchange_tweet_counts, data = .))

results2 <- tidy(fits2, mod) %>% filter(term=='scale_pchange_tweet_counts') 

#Plot p-values and see symbols that have significant results
results2 %>% 
  ggplot(aes(symbol, p.value, color=symbol)) + geom_point() + geom_hline(yintercept = .05, color = 'red') +
  geom_text_repel(aes(symbol, p.value, label=symbol), data = filter(results2,  p.value <.05 )) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("P-values for Normalized percent change in Price by Hour") +
  theme(legend.position = "none")  

#Fit linear models - avg_score + tweet_counts by day
fits3 <- dat.byday %>%
  group_by(symbol) %>%
  do(mod = lm(price ~ avg_score + tweet_counts, data = .))

results3 <- tidy(fits3, mod) %>% filter(term=='avg_score') 

#Plot p-values and see symbols that have significant results
results3 %>% 
  ggplot(aes(symbol, p.value, color=symbol)) + geom_point() + geom_hline(yintercept = .05, color = 'red') +
  geom_text_repel(aes(symbol, p.value, label=symbol), data = filter(results3,  p.value <.05 )) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("P-values for Price by Day") +
  theme(legend.position = "none") 

#Fit linear models by day - percent change in avg_score + tweet_counts by day
fits4 <- dat.byday %>%
  group_by(symbol) %>%
  do(mod = lm(scale_pchange_price_change ~ scale_pchange_avg_score + scale_pchange_tweet_counts, data = .))

results4 <- tidy(fits4, mod) %>% filter(term=='scale_pchange_tweet_counts') 

#Plot p-values and see symbols that have significant results
results4 %>% 
  ggplot(aes(symbol, p.value, color=symbol)) + geom_point() + geom_hline(yintercept = .05, color = 'red') +
  geom_text_repel(aes(symbol, p.value, label=symbol), data = filter(results4,  p.value <.05 )) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("P-values for Normalized percent change in Price by Day") +
  theme(legend.position = "none") 

```

#### Placeholder for Words Infographics

```{r, echo=FALSE, message=FALSE, warning=FALSE}
words <- cbind(c('up','rise','hike'), c(10, 4, 2), c('positive', 'positive', 'positive'))
colnames(words) <- c('words','counts', 'label')
words <- rbind(words,cbind(c('fail','down','discredit'), c(1, 9, 5), c('negative', 'negative', 'negative')))
words <- as.data.frame(words)
library(ggplot2)
library(ggrepel)
ggplot(data=words, aes(x=words,y=counts, size=counts, color=as.factor(label))) + 
  geom_point() +
  geom_text_repel(aes(words, counts, label=words)) + 
  theme(legend.position = "none") +
  theme(axis.text.x = element_blank()) +
  labs(title="Words Inforgraphics", y="Counts", x="Positive or Negative Sentiment Words")

```
