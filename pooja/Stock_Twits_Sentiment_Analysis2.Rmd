---
title: "Stock_Twits_Sentiment_Analysis"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
if (!require("dplyr")) {
   install.packages("dplyr", dependencies = TRUE)
   }
if (!require("readr")) {
   install.packages("readr", dependencies = TRUE)
   }
if (!require("stringr")) {
   install.packages("stringr", dependencies = TRUE)
   }
if (!require("ggplot2")) {
   install.packages("ggplot2", dependencies = TRUE)
   }
if (!require("broom")) {
   install.packages("broom", dependencies = TRUE)
   }
if (!require("lubridate")) {
   install.packages("lubridate", dependencies = TRUE)
   }
if (!require("ggrepel")) {
   install.packages("ggrepel", dependencies = TRUE)
   }
if (!require("RColorBrewer")) {
   install.packages("RColorBrewer", dependencies = TRUE)
   }
if (!require("gplots")) {
  install.packages("gplots", dependencies = TRUE)
}
if (!require("portfolio")) {
  install.packages("portfolio")
}
library(dplyr)
library(readr)
library(stringr)
library(ggplot2)
library(broom)
library(lubridate)
library(ggrepel)
library(RColorBrewer)
library(gplots)
library(portfolio)
   

#Supress warnings
options(warn=-1)

#read stick-twits_sentiments generate from stock_twits_processing.R file
#data <- read_csv(file = "https://raw.githubusercontent.com/goodwillyoga/E107project/master/pooja/data/stock_twits_sentiment_score3.csv")[-1]
data <- read_csv(file = "https://raw.githubusercontent.com/goodwillyoga/E107project/master/pooja/stock_twits_sentiment_score_na.csv")
colnames(data)[1] <- "id"
colnames(data)[2] <- "message"
colnames(data)[3] <- "createdat"
colnames(data)[4] <- "symbol"
colnames(data)[5] <- "sentiment_score"
length(data$id)

#Convert to UTC to EST time zone 
data <- data %>% mutate(utc.time = as.POSIXct(data$createdat, tz="UTC")) %>%
                 mutate(est.time = format(utc.time, tz="America/New_York")) %>%
                 mutate(est.date = substr(as.character(format(strftime(est.time, '%m/%d/%Y'))), 2,10)) %>%
                 mutate(est.hour = paste(est.date, hour(est.time)))

#Percent change function
pcchange=function(x,lag=1) {
  c(diff(x,lag))/x
}

#Get hour from time function
get_24hour <- function(x){
  ret <- ''
  splitVector<- strsplit(x,':')
  ret <- sapply(splitVector, function(z){
    if(str_count(z[2],'AM')|str_count(z[2],'am')){
      paste( z[1])
    }else{
      paste( ifelse(as.numeric(z[1]) == 12,12, as.numeric(z[1])+12 ))
    }
  })
  return(ret)
}

# Scale function
scale<-function(m){
  (m - mean(m))/sd(m)
}

#Average sentiment score by hour
avg_sentiment_score_by_hour <- data %>% 
            group_by(symbol, dayhour = est.hour) %>%
            summarise(avg_score = mean(sentiment_score), tweet_counts = n()) %>%
            mutate(pchange_tweet_counts = pcchange(tweet_counts)) %>%
            mutate(pchange_avg_score = pcchange(avg_score)) %>%
            mutate(pchange_avg_score = ifelse(is.na(pchange_avg_score) | is.infinite(pchange_avg_score) |is.nan(pchange_avg_score), 0, pchange_avg_score)) %>%
            ungroup() %>%
            group_by(symbol) %>%
            mutate(scale_pchange_avg_score = scale(pchange_avg_score)) %>% 
            mutate(scale_pchange_tweet_counts = scale(pchange_tweet_counts)) %>% 
            mutate(scale_pchange_avg_score = ifelse(is.na(scale_pchange_avg_score) | is.infinite(scale_pchange_avg_score) |is.nan(scale_pchange_avg_score), 0, scale_pchange_avg_score)) %>%
            ungroup() %>%
            select(symbol, dayhour, avg_score, tweet_counts, scale_pchange_avg_score, scale_pchange_tweet_counts) %>%
            unique() 

#Average sentiment score by day
avg_sentiment_score_by_day <- data %>% 
            group_by(symbol, day=est.date) %>%
            summarise(avg_score = mean(sentiment_score), tweet_counts = n()) %>%
            mutate(pchange_tweet_counts = pcchange(tweet_counts)) %>%
            mutate(pchange_avg_score = pcchange(avg_score)) %>%
            mutate(pchange_avg_score = ifelse(is.na(pchange_avg_score) | is.infinite(pchange_avg_score) |is.nan(pchange_avg_score), 0, pchange_avg_score)) %>%
            ungroup() %>%
            group_by(symbol) %>%
            mutate(scale_pchange_avg_score = scale(pchange_avg_score)) %>% 
            mutate(scale_pchange_tweet_counts = scale(pchange_tweet_counts)) %>% 
            mutate(scale_pchange_avg_score = ifelse(is.na(scale_pchange_avg_score) | is.infinite(scale_pchange_avg_score) |is.nan(scale_pchange_avg_score), 0, scale_pchange_avg_score)) %>%
            ungroup() %>%
            select(symbol, day, avg_score, tweet_counts, scale_pchange_avg_score, scale_pchange_tweet_counts) %>%
            unique() 
 
#Load YAHOO finance data
load("/Users/poojasingh/Documents/HE107/E107project/pulkit/yahoo-finance.RData")

##Average Stock Price by hour
avg_stocks_price_by_hour <- stocks %>% 
                   mutate(dayhour = paste(lastTradeDate,get_24hour(lastTradeTime))) %>%
                   group_by(symbol, dayhour) %>%
                   summarise(price = mean(price)) %>%
                   mutate(pchange_price_change = pcchange(price)) %>%
                   mutate(pchange_price_change = ifelse(is.na(pchange_price_change) | is.infinite(pchange_price_change) |is.nan(pchange_price_change), 0, pchange_price_change)) %>%
                   ungroup() %>%
                   group_by(symbol) %>%
                   mutate(scale_pchange_price_change = scale(pchange_price_change)) %>% 
                   mutate(scale_pchange_price_change = ifelse(is.na(scale_pchange_price_change) | is.infinite(scale_pchange_price_change) |is.nan(scale_pchange_price_change), 0, scale_pchange_price_change)) %>%
                   ungroup() %>%
                   select(symbol, dayhour, price, scale_pchange_price_change) %>%
                   unique()

#Average Stock Price by day
avg_stocks_price_by_day <- stocks %>% 
                  group_by(symbol, day=lastTradeDate) %>%
                  summarise(price = mean(price), volume = max(volume)) %>%
                  mutate(pchange_price_change = pcchange(price)) %>%
                  mutate(pchange_volume = pcchange(volume)) %>%
                  mutate(pchange_price_change = ifelse(is.na(pchange_price_change) | is.infinite(pchange_price_change) |is.nan(pchange_price_change), 0, pchange_price_change)) %>%
                  mutate(pchange_volume = ifelse(is.na(pchange_volume) | is.infinite(pchange_volume) |is.nan(pchange_volume), 0, pchange_volume)) %>%
                  ungroup() %>%
                  group_by(symbol) %>%
                  mutate(scale_pchange_price_change = scale(pchange_price_change)) %>% 
                  mutate(scale_pchange_volume = scale(pchange_volume)) %>% 
                  mutate(scale_pchange_price_change = ifelse(is.na(scale_pchange_price_change) | is.infinite(scale_pchange_price_change) |is.nan(scale_pchange_price_change), 0, scale_pchange_price_change)) %>%
                  mutate(scale_pchange_volume = ifelse(is.na(scale_pchange_volume) | is.infinite(scale_pchange_volume) |is.nan(scale_pchange_volume), 0, scale_pchange_volume)) %>%
                  ungroup() %>%
                  select(symbol, day, price, scale_pchange_price_change, scale_pchange_volume) %>%
                  unique()

#Join score and price
dat <- inner_join(avg_stocks_price_by_hour, avg_sentiment_score_by_hour)
dat.byday <- inner_join(avg_stocks_price_by_day, avg_sentiment_score_by_day)

#Plot overlay denisty plots for perchange change in stock price and percent change in sentiment_score
dat3 <- subset(dat, symbol=="EIX")
dat3 <- data.frame(Normalized_Percent_Change_By_Hour = c(dat3$scale_pchange_price_change, dat3$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat3$scale_pchange_price_change)))
dat3 <- cbind(dat3, symbol="EIX")

dat4 <- subset(dat, symbol=="GS")
dat4 <- data.frame(Normalized_Percent_Change_By_Hour = c(dat4$scale_pchange_price_change, dat4$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat4$scale_pchange_price_change)))
dat4 <- cbind(dat4, symbol="GS")

dat5 <- subset(dat, symbol=="IBM")
dat5 <- data.frame(Normalized_Percent_Change_By_Hour = c(dat5$scale_pchange_price_change, dat5$scale_pchange_avg_score)
                   , lines = rep(c("Normalized percent change in price", "Normalized percent change in sentiment score"), each = length(dat5$scale_pchange_price_change)))
dat5 <- cbind(dat5, symbol="IBM")

#EDA for positive words and negative words 
#Count all positive words that were matched in stocktwits messages
posWords <- read_csv(file = "https://raw.githubusercontent.com/goodwillyoga/E107project/master/pooja/posWords_na.csv")
colnames(posWords)[1] <- c('words')
posWords <- posWords %>% group_by(words) %>% summarize(counts=n())
len <- length(posWords$words)
posWords <- cbind(posWords, rep('positive',len))
colnames(posWords)[3] <- c('sentiment')

#Count all negative words that were matched in message stocktwits messages
negWords <- read_csv(file = "https://raw.githubusercontent.com/goodwillyoga/E107project/master/pooja/negWords_na.csv")
colnames(negWords)[1] <- c('words')
negWords <- negWords %>% group_by(words) %>% summarize(counts=n())
len <- length(negWords$words)
negWords <- cbind(negWords, rep('negative',len))
colnames(negWords)[3] <- c('sentiment')
 
#Combine al the positive and nagative words and select top 20 frquently used positive words and negative words
words <- rbind(posWords, negWords)
freqwords <- words %>% filter(sentiment=='positive') %>% top_n(50,counts)
freqwords <- rbind(freqwords, words %>% filter(sentiment=='negative') %>% top_n(50,counts))
```

### Methodology for extraction of Data - StockTwits 
  We follwed a similar approach as for Twitter data to collect tweets for the chosen stocks for three weeks from [StockTwits](https://api.stocktwits.com/api/2/streams/symbol/AAPL.json). The data gathering, cleaning and processing steps can be summarized as below
  
  ![StockTwits Workflow](https://github.com/goodwillyoga/E107project/blob/master/pooja/StockTwitsProcess.png?raw=true)
  
In the [stock-twits_multiple.R](https://raw.githubusercontent.com/goodwillyoga/E107project/master/pooja/stock-twits_multiple.R) file we make an API call, to StockTwits for a given symbol every 15 minutes for 3 weeks, that returns response in JSON. We use rjson library to extract the id, message, timestamp and symbol from the JSON response. 

TODO PUT THE SAMPLE HERE

Next we aggregate collected data in  [stock-twits-processing.R](https://raw.githubusercontent.com/goodwillyoga/E107project/master/pooja/stock-twits-processing.R) file and cleanup duplicate messages. We then calculate the sentiment score for each tweet( or message) by taking the counts of postive terms minus the counts of negative terms in a tweet as explained in a paper [here](http://www.r-bloggers.com/an-example-on-sentiment-analysis-with-r/). We used [AFINN](http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010) word list and English Opinion Lexicon positive and negative word lists to compare the words in a tweet to determine if it is a postiver term or a negative term to calculate the sentiment score. 

In the final modelling step in [stock-twits-analysis.R](https://raw.githubusercontent.com/goodwillyoga/E107project/master/pooja/stock-twits-analysis.R) file, we combine the StockTwits data and [Yahoo! finance data](https://github.com/goodwillyoga/E107project/blob/master/pulkit/yahoo-finance.RData) to model the stock price based on the tweet counts and sentiment scores.

Next we proceed with exploratory data analysis. 


#### Exploratory Data Analysis for Stock Twits Data

1. We plotted heatmap to show the stock price and tweet counts for all chosen symbols. The area for each symbol in the heatmap represents the price of the stock for a given day. The color scale represents the tweet counts with lighter green reperenting more number of tweet counts for a given symbol. (This data visualization be extended to a Shiny app in the future, where we can present user a date picker and they can see the heatmap for a given day)


```{r, echo=FALSE, message=FALSE, warning=FALSE}
dat.plot <- 
  dat.byday %>% select(symbol, day, price, tweet_counts) %>%
  filter(day == "4/19/2016") %>%
  mutate(price=round(price)) %>%
  select(symbol, round(price), tweet_counts) 

map.market(id=dat.plot$symbol, area=dat.plot$price, group=dat.plot$symbol, color=dat.plot$tweet_counts, main="Stock Price and Tweet counts", lab=c(FALSE,TRUE))
```

2. We plotted the heatmap for the top 50 positive and negative matched words in StockTwits messages. The area and color in the heatmap represents the counts for matched words.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
map.market(id=freqwords$words, area=freqwords$counts, group=freqwords$words, color=freqwords$counts, main="Top 50 Positive and Negative Sentiment Words", lab=c(FALSE,TRUE))
```

3. We plotted the density plot of normalized hourly percent change in sentiment score and price change for three chosen stocks (EIX, IBM, and GS).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Overlay Density Plot
datz <- rbind(dat3, dat5, dat4)
datz %>% 
  ggplot(aes(x = Normalized_Percent_Change_By_Hour, fill = lines)) + geom_density(alpha = 0.5) + 
  facet_wrap(~symbol) +
  theme(legend.position="bottom") +
  labs(title='Density plot of sentiment score and price change')
```

#### Plot p-values for linear regression fit model

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Fit linear models - avg_score + tweet_counts by hour
fits1 <- dat %>%
  group_by(symbol) %>%
  do(mod = lm(price ~ avg_score + tweet_counts, data = .))

results1 <- tidy(fits1, mod) %>% filter(term=='avg_score') 

#Plot p-values and see symbols that have significant results
results1 %>% 
  ggplot(aes(symbol, p.value, color=symbol)) + geom_point() + geom_hline(yintercept = .05, color = 'red') +
  geom_text_repel(aes(symbol, p.value, label=symbol), data = filter(results1,  p.value <.05 )) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("P-values for Price by Hour") +
  theme(legend.position = "none") 

#Fit linear models - percent change in avg_score + tweet_counts by hour
fits2 <- dat %>%
  group_by(symbol) %>%
  do(mod = lm(scale_pchange_price_change ~ scale_pchange_avg_score + scale_pchange_tweet_counts, data = .))

results2 <- tidy(fits2, mod) %>% filter(term=='scale_pchange_tweet_counts') 

#Plot p-values and see symbols that have significant results
results2 %>% 
  ggplot(aes(symbol, p.value, color=symbol)) + geom_point() + geom_hline(yintercept = .05, color = 'red') +
  geom_text_repel(aes(symbol, p.value, label=symbol), data = filter(results2,  p.value <.05 )) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("P-values for Normalized percent change in Price by Hour") +
  theme(legend.position = "none")  

#Fit linear models - avg_score + tweet_counts by day
fits3 <- dat.byday %>%
  group_by(symbol) %>%
  do(mod = lm(price ~ avg_score + tweet_counts, data = .))

results3 <- tidy(fits3, mod) %>% filter(term=='avg_score') 

#Plot p-values and see symbols that have significant results
results3 %>% 
  ggplot(aes(symbol, p.value, color=symbol)) + geom_point() + geom_hline(yintercept = .05, color = 'red') +
  geom_text_repel(aes(symbol, p.value, label=symbol), data = filter(results3,  p.value <.05 )) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("P-values for Price by Day") +
  theme(legend.position = "none") 

#Fit linear models by day - percent change in avg_score + tweet_counts by day
fits4 <- dat.byday %>%
  group_by(symbol) %>%
  do(mod = lm(scale_pchange_price_change ~ scale_pchange_avg_score + scale_pchange_tweet_counts, data = .))

results4 <- tidy(fits4, mod) %>% filter(term=='scale_pchange_tweet_counts') 

#Plot p-values and see symbols that have significant results
results4 %>% 
  ggplot(aes(symbol, p.value, color=symbol)) + geom_point() + geom_hline(yintercept = .05, color = 'red') +
  geom_text_repel(aes(symbol, p.value, label=symbol), data = filter(results4,  p.value <.05 )) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("P-values for Normalized percent change in Price by Day") +
  theme(legend.position = "none") 

```



